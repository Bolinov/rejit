#!/usr/bin/python

import os
from os.path import join, dirname, realpath
import sys
import subprocess

# Used to generate random characters.
import random
# Used to compute the scores.
import math

scriptpath = dirname(realpath(__file__))
dir_tools = join(scriptpath, '../../../../')
sys.path.insert(0, dir_tools)
import utils
from utils import *
import gc

import argparse
help_description='''
Benchmark v8 regular expression engine.
Outputs the amortised processing speed in bytes/s (<size of text matched> / <time to match>)
considering (<--iterations=?> runs and 1 compilation).
'''
parser = argparse.ArgumentParser(description=help_description)
parser.add_argument("regexp" , help="The regular expression to benchmark.")
parser.add_argument("--file"       ,            default=""   , help="Source file. If none provided        , use a randomly generated characters.")
parser.add_argument("--size"       , type=int , default=65536, help="Size of the text to match.")
parser.add_argument("--iterations" , type=int , default=1000 , help="Number of iterations to run.")
parser.add_argument("--low_char"   ,            default="0"  , help="When the match source is random text , the low character of the range of characters composing the matched text.")
parser.add_argument("--high_char"  ,            default="z"  , help="When the match source is random text , the high character of the range of characters composing the matched text.")

path_d8 = join(dir_benchmarks_engines, 'v8/git.v8/out/native/d8')

# TODO: faster implementation?
def random_text(size, low = '0', high = 'z'):
  chars = ''.join([chr(i) for i in range(ord(low), ord(high)) if i not in [ord(';'), ord('"'), ord('\\')]])
  return ''.join(random.choice(chars) for x in range(size))

def run():
  args = parser.parse_args()

  # Decide where the benchmark files will be created.
  dir_testfiles = join(dir_benchmarks_engines, 'v8', 'test_files')
  if not os.path.exists(dir_testfiles):
    os.makedirs(dir_testfiles)

  # The parameters should be embedded in the file names.
  # Writing those files in python is slow, and this allows us to reuse them.
  text_file_path = join(dir_testfiles, 'text.' + args.low_char + args.high_char + str(args.size) + '.js')
  if not os.path.exists(text_file_path):
    text_file = open(text_file_path, 'w')
    text = random_text(args.size, args.low_char, args.high_char)
    text_file.write(' var text = "%s"; ' % text)
    text_file.close()

  dic = {
      'regexp': args.regexp,
      'size': args.size,
      'iterations': args.iterations,
      'modifier': 'g'}
  run_file_path = join(dir_testfiles, 'run.js')
  run_file = open(run_file_path, 'w')
  run_file.write('''
function main() {
  var regexp     = /%(regexp)s/%(modifier)s;
  var size       = %(size)s;
  var iterations = %(iterations)s;
  var t0 = new Date();
  for (var i = 0; i < iterations; i++) {
    regexp.exec(text);
  }
  var tdiff = new Date() - t0;
  print(size / tdiff * 1000 * iterations)
}
main();
''' % dic)
  run_file.close()

  command_args = [path_d8, text_file_path, run_file_path]
  p = subprocess.Popen(command_args , stdout=subprocess.PIPE)
  ret = p.wait()
  out = p.communicate()
  outs = out[0].rstrip(' \n\r\t').lstrip(' \n\r\t')
  if ret != 0 or outs == 'Infinity':
    print '0'
  else:
    print outs

if __name__ == "__main__":
  run()
